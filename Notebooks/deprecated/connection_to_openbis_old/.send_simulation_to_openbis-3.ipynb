{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AiiDA imports.\n",
    "%load_ext aiida\n",
    "%aiida\n",
    "from aiida import common, orm\n",
    "from surfaces_tools.widgets import series_plotter\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import utils\n",
    "import ipywidgets as ipw\n",
    "from app_widgets import AppWidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEWERS = {\n",
    "    \"CP2K_AdsorptionE\": \"view_adsorption_energy.ipynb\",\n",
    "    \"CP2K_GeoOpt\": \"view_geometry_optimization.ipynb\",\n",
    "    \"CP2K_CellOpt\": \"view_geometry_optimization.ipynb\",\n",
    "    \"CP2K_ORBITALS\": \"view_orbitals.ipynb\",\n",
    "    \"CP2K_PDOS\": \"view_pdos.ipynb\",\n",
    "    \"CP2K_STM\": \"view_stm.ipynb\",\n",
    "    \"CP2K_AFM\": \"view_afm.ipynb\",\n",
    "    \"CP2K_HRSTM\": \"view_hrstm.ipynb\",\n",
    "    \"CP2K_Phonons\": \"view_phonons.ipynb\",\n",
    "    \"CP2K_NEB\": \"view_neb.ipynb\",\n",
    "    \"CP2K_Replica\": \"view_replica.ipynb\",\n",
    "    \"ReplicaWorkChain\": \"view_replica.ipynb\",\n",
    "}\n",
    "\n",
    "def uuids_to_nodesdict(uuids):\n",
    "    workflows = {}\n",
    "    nworkflows = 0\n",
    "    for uuid in uuids:\n",
    "        try:\n",
    "            node = orm.load_node(uuid)\n",
    "            nodeisobsolete = \"obsolete\" in node.extras and node.extras[\"obsolete\"]\n",
    "            if node.label in VIEWERS and not nodeisobsolete:\n",
    "                nworkflows += 1\n",
    "                if node.label in workflows:\n",
    "                    workflows[node.label].append(node)\n",
    "                else:\n",
    "                    workflows[node.label] = [node]\n",
    "        except common.NotExistent:\n",
    "            pass\n",
    "\n",
    "    return nworkflows, workflows\n",
    "\n",
    "def get_all_structures_and_geoopts(node):\n",
    "    \"\"\"Get all atomistic models that led to the one used in the STM simulation\"\"\"\n",
    "    current_node = node\n",
    "    all_structures = [node]\n",
    "    all_geoopts = []\n",
    "    while current_node is not None:\n",
    "        if isinstance(current_node, orm.StructureData):\n",
    "            current_node = current_node.creator\n",
    "        elif isinstance(current_node, orm.CalcJobNode):\n",
    "            current_node = current_node.caller\n",
    "            \n",
    "        elif isinstance(current_node, orm.WorkChainNode):\n",
    "            if \"GeoOpt\" in current_node.label:\n",
    "                all_geoopts.append(current_node)\n",
    "                current_node = current_node.inputs.structure\n",
    "                all_structures.append(current_node)\n",
    "            else:\n",
    "                current_node = current_node.caller\n",
    "    \n",
    "    return all_structures, all_geoopts\n",
    "\n",
    "def get_workflows(start_date, end_date):\n",
    "    qb = orm.QueryBuilder()\n",
    "    qb.append(\n",
    "        orm.StructureData,\n",
    "        filters={\n",
    "            \"extras\": {\"has_key\": \"surfaces\"},\n",
    "            \"mtime\": {\"and\": [{\"<=\": end_date}, {\">\": start_date}]},\n",
    "        },\n",
    "    )\n",
    "    qb.order_by({orm.StructureData: {\"mtime\": \"desc\"}})\n",
    "\n",
    "    # For each structure in QB create a dictionary with info on the workflows computed on it.\n",
    "    data = []\n",
    "    for node in qb.all(flat=True):\n",
    "        # print(\"node \", node.pk, \" extras \", node.extras[\"surfaces\"])\n",
    "        extras = node.extras[\"surfaces\"]\n",
    "        nworkflows = 0\n",
    "        if isinstance(extras, list):\n",
    "            nworkflows, workflows = uuids_to_nodesdict(node.extras[\"surfaces\"])\n",
    "        if nworkflows > 0:\n",
    "            data.append(workflows)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "config = utils.read_json(\"config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send simulation to openBIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.fa-save {font-size: 2em !important; /* Increase icon size */}.fa-home {font-size: 2em !important; /* Increase icon size */}.fa-times {font-size: 2em !important; /* Increase icon size */}.fa-download {font-size: 2em !important; /* Increase icon size */}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise app widgets\n",
    "app_widgets = AppWidgets(\"config.json\")\n",
    "app_widgets.load_dropdown_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select experiment and molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(app_widgets.select_experiment_output)\n",
    "with app_widgets.select_experiment_output:\n",
    "    display(app_widgets.experiments_dropdown_boxes, app_widgets.molecule_metadata_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as datetime\n",
    "end_date = datetime.datetime.now()\n",
    "start_date = end_date - datetime.timedelta(days=20)\n",
    "data = get_workflows(start_date, end_date)\n",
    "\n",
    "all_workflows = []\n",
    "for workflows in data:\n",
    "    workflows = workflows.values()\n",
    "    workflows = list(workflows)[0]\n",
    "    all_workflows.extend(workflows)\n",
    "\n",
    "workflows_dropdown = utils.Dropdown(description='Workflows', disabled=False, layout = ipw.Layout(width = '993px'), style = {'description_width': \"110px\"}, options = all_workflows)\n",
    "display(workflows_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_simulations(b):\n",
    "    selected_experiment_identifier = app_widgets.experiments_dropdown.value\n",
    "    \n",
    "    # Get STM Simulation Workchain from AiiDA\n",
    "    stm_workchain_node = workflows_dropdown.value\n",
    "    stm_workchain_pk = stm_workchain_node.pk\n",
    "    structure_stm = stm_workchain_node.inputs.structure\n",
    "    structure_stm_pk = structure_stm.pk\n",
    "    structure_stm_node = load_node(structure_stm_pk)\n",
    "\n",
    "    # Get Geometry Optimisation Workchain from AiiDA\n",
    "    all_atom_mods, all_geoopts = get_all_structures_and_geoopts(structure_stm_node)\n",
    "    all_exist_openbis_atom_mods, all_exist_openbis_geoopts, all_exist_openbis_stms = [], [], []\n",
    "    \n",
    "    # Get all simulations and atomistic models from openbis\n",
    "    openbis_geoopts = app_widgets.openbis_session.get_objects(type = \"GEOMETRY_OPTIMISATION\")\n",
    "    openbis_atom_mods = app_widgets.openbis_session.get_objects(type = \"ATOMISTIC_MODEL\")\n",
    "    openbis_stms = app_widgets.openbis_session.get_objects(type = \"2D_MEASUREMENT\")\n",
    "    \n",
    "    # Verify which GeoOpts are already in openBIS\n",
    "    for aiida_geoopt_idx, aiida_geoopt in enumerate(all_geoopts):\n",
    "        exists_openbis_geoopt = False\n",
    "        for openbis_geoopt in openbis_geoopts:\n",
    "            if openbis_geoopt.props.get(\"wfms-uuid\") == aiida_geoopt.uuid:\n",
    "                all_exist_openbis_geoopts.append([openbis_geoopt, True])\n",
    "                exists_openbis_geoopt = True\n",
    "                print(f\"GeoOpt {openbis_geoopt.props.get('wfms-uuid')} already exists.\")\n",
    "\n",
    "        if exists_openbis_geoopt == False:\n",
    "            all_exist_openbis_geoopts.append([None, False])\n",
    "    \n",
    "    # Reverse the lists because in openBIS, one should start by building the parents.\n",
    "    all_geoopts.reverse()\n",
    "    all_exist_openbis_geoopts.reverse()\n",
    "    \n",
    "    # Verify which structures (atomistic models) are already in openBIS\n",
    "    for aiida_atom_mod_idx, aiida_atom_mod in enumerate(all_atom_mods):\n",
    "        exists_openbis_atom_mod = False\n",
    "        for openbis_atom_mod in openbis_atom_mods:\n",
    "            if openbis_atom_mod.props.get(\"wfms-uuid\") == aiida_atom_mod.uuid:\n",
    "                all_exist_openbis_atom_mods.append([openbis_atom_mod, True])\n",
    "                exists_openbis_atom_mod = True\n",
    "                print(f\"Atomistic model {openbis_atom_mod.props.get('wfms-uuid')} already exists.\")\n",
    "            \n",
    "        if exists_openbis_atom_mod == False:\n",
    "            all_exist_openbis_atom_mods.append([None, False])\n",
    "    \n",
    "    # Reverse the lists because in openBIS, one should start by building the parents.\n",
    "    all_atom_mods.reverse()\n",
    "    all_exist_openbis_atom_mods.reverse()\n",
    "    \n",
    "    # Verify which simulations are already in openBIS\n",
    "    exists_openbis_stm = False\n",
    "    for openbis_stm in openbis_stms:\n",
    "        if openbis_stm.props.get(\"wfms-uuid\") == stm_workchain_node.uuid:\n",
    "            all_exist_openbis_stms.append([openbis_stm, True])\n",
    "            print(f\"STM {openbis_stm.props.get('wfms-uuid')} already exists.\")\n",
    "        \n",
    "    if exists_openbis_stm == False:\n",
    "        all_exist_openbis_stms.append([None, False])\n",
    "\n",
    "    # Build atomistic models (structures in AiiDA) in openBIS\n",
    "    all_atomistic_models = []\n",
    "    \n",
    "    for atom_mod_idx, atom_mod in enumerate(all_atom_mods):\n",
    "        exists_openbis_atom_mod = all_exist_openbis_atom_mods[atom_mod_idx]\n",
    "        \n",
    "        if exists_openbis_atom_mod[1] == False:\n",
    "            # Get Structure details from AiiDA\n",
    "            atom_mod_ase = atom_mod.get_ase()\n",
    "            atoms_positions = {'coordinates': {'has_value': [], 'has_unit': 'unit:ANGSTROM'}, 'atoms_symbols': []}\n",
    "            for i, atom_symbol in enumerate(atom_mod_ase.symbols):\n",
    "                atoms_positions[\"coordinates\"][\"has_value\"].append(list(atom_mod_ase.positions[i]))\n",
    "                atoms_positions['atoms_symbols'].append(atom_symbol)\n",
    "\n",
    "            # Create Atomistic Model in openBIS\n",
    "            atomistic_model = app_widgets.openbis_session.new_sample(collection = \"/MATERIALS/ATOMISTIC_MODELS/ATOMISTIC_MODEL_COLLECTION\", type='ATOMISTIC_MODEL')\n",
    "            \n",
    "            atomistic_model.props['$name'] = \"Atomistic Model 1\"\n",
    "            atomistic_model.props['wfms_uuid'] = atom_mod.uuid\n",
    "            # atomistic_model.props['cell_vectors'] = json.dumps({'has_value': atom_mod.cell, 'has_unit': 'unit:ANGSTROM'})\n",
    "            # atomistic_model.props['periodic_boundary_conditions'] = [int(i) for i in atom_mod_ase.pbc]\n",
    "            # atomistic_model.props['atoms_positions'] = json.dumps(atoms_positions)\n",
    "            \n",
    "            # if len(all_atom_mods) > 1 and atom_mod_idx == len(all_atom_mods) - 1: # If it is the last of more than one structures, it is optimised.\n",
    "            #     atomistic_model.props['optimised'] = True\n",
    "            # else:\n",
    "            #     atomistic_model.props['optimised'] = False\n",
    "            atomistic_model.save()\n",
    "            \n",
    "            all_atomistic_models.append(atomistic_model)\n",
    "        else:\n",
    "            all_atomistic_models.append(exists_openbis_atom_mod[0])\n",
    "    \n",
    "    # Build GeoOpts in openBIS\n",
    "    all_geoopts_models = []\n",
    "    \n",
    "    for geoopt_index, geoopt in enumerate(all_geoopts):\n",
    "        geoopt_exist_openbis = all_exist_openbis_geoopts[geoopt_index]\n",
    "        \n",
    "        if geoopt_exist_openbis[1] == False:\n",
    "            parent_atomistic_model = all_atomistic_models[geoopt_index]\n",
    "            geoopt_model = app_widgets.openbis_session.new_sample(experiment = selected_experiment_identifier, type = 'GEOMETRY_OPTIMISATION', parents = [parent_atomistic_model])\n",
    "            geoopt_model.props['$name'] = \"GeoOpt Simulation\"\n",
    "            geoopt_model.props['wfms_uuid'] = geoopt.uuid\n",
    "            geoopt_model.save()\n",
    "            \n",
    "            # Its plus one because there are N+1 geometries for N GeoOpts\n",
    "            all_atomistic_models[geoopt_index + 1].add_parents(geoopt_model)\n",
    "            all_atomistic_models[geoopt_index + 1].save()\n",
    "            \n",
    "            all_geoopts_models.append(geoopt_model)\n",
    "        else:\n",
    "            all_geoopts_models.append(geoopt_exist_openbis[0])\n",
    "    \n",
    "    # Build STM simulation in openBIS\n",
    "    \n",
    "    if all_exist_openbis_stms[0][1] == False:\n",
    "        # Get DFT parameters\n",
    "        dft_params = dict(stm_workchain_node.inputs.dft_params)\n",
    "        \n",
    "        # Simulated Scanning Tunneling Microscopy\n",
    "        optimised_atomistic_model = all_atomistic_models[-1]\n",
    "        stm = app_widgets.openbis_session.new_sample(experiment = selected_experiment_identifier, type = '2D_MEASUREMENT', parents = [optimised_atomistic_model])\n",
    "        stm.props['$name'] = \"Simulation STM\"\n",
    "        stm.props['wfms_uuid'] = stm_workchain_node.uuid\n",
    "        \n",
    "        # stm_params = dict(stm_workchain_node.inputs.spm_params)\n",
    "        # stm.props['e_min'] = json.dumps({'has_value': stm_params['--energy_range'][0], 'has_unit': 'unit:EV'})\n",
    "        # stm.props['e_max'] = json.dumps({'has_value': stm_params['--energy_range'][1], 'has_unit': 'unit:EV'})\n",
    "        # stm.props['de'] = json.dumps({'has_value': stm_params['--energy_range'][2], 'has_unit': 'unit:EV'})\n",
    "        \n",
    "        # stm.props['fwhm'] = json.dumps({'has_value': [float(x) for x in stm_params['--fwhms']], 'has_unit': 'unit:EV'})\n",
    "        # # stm.props['extrap_plane'] = json.dumps({'has_value': stm_params['--energy_range'][2], 'has_unit': 'unit:ANGSTROM'})\n",
    "        # stm.props['constant_height'] = json.dumps({'has_value': [float(x) for x in stm_params['--heights']], 'has_unit': 'unit:ANGSTROM'})\n",
    "        # stm.props['constant_current'] = json.dumps({'has_value': [float(x) for x in stm_params['--isovalues']], 'has_unit': 'isovalue'})\n",
    "        stm.save()\n",
    "        \n",
    "        # stm_simulation_images_zip_filename = series_plotter_inst.create_zip_link_for_openbis()\n",
    "        \n",
    "        # stm_simulation_images_dataset = session.new_dataset(\n",
    "        #     type = \"RAW_DATA\", \n",
    "        #     files = [stm_simulation_images_zip_filename],\n",
    "        #     sample = stm_simulation_model\n",
    "        # )\n",
    "        # stm_simulation_images_dataset.save()\n",
    "\n",
    "        stm_dataset_filename = \"stm_simulation.aiida\"\n",
    "        os.system(f\"verdi archive create {stm_dataset_filename} --no-call-calc-backward --no-call-work-backward --no-create-backward -N {stm_workchain_pk}\")\n",
    "\n",
    "        stm_dataset = app_widgets.openbis_session.new_dataset(\n",
    "            type = \"RAW_DATA\", \n",
    "            files = [stm_dataset_filename],\n",
    "            sample = stm\n",
    "        )\n",
    "        stm_dataset.save()\n",
    "\n",
    "        # Delete the file after uploading\n",
    "        os.remove(stm_dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292fc28694054888be70a94ed97722bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Objects'), Button(description='Add molecule', style=ButtonStyle()), Button(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ef24775e554d57b4a28f60113c854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add_objects_label = ipw.Label(value = \"Objects\")\n",
    "# add_molecule_button = utils.Button(description = \"Add molecule\")\n",
    "# add_slab_button = utils.Button(description = \"Add slab\")\n",
    "# add_product_button = utils.Button(description = \"Add product\")\n",
    "# add_objects_hbox = ipw.HBox([add_objects_label, add_molecule_button, add_slab_button, add_product_button])\n",
    "# added_objects_accordion = ipw.Accordion()\n",
    "\n",
    "# def add_molecule_button_action(b):\n",
    "#     added_objects_accordion_children = list(added_objects_accordion.children)\n",
    "#     added_objects_accordion.set_title(len(added_objects_accordion_children), \"Molecule\")\n",
    "#     added_objects_accordion_children.append(utils.Text(description = \"Molecule\"))\n",
    "#     added_objects_accordion.children = added_objects_accordion_children\n",
    "    \n",
    "# def add_slab_button_action(b):\n",
    "#     added_objects_accordion_children = list(added_objects_accordion.children)\n",
    "#     added_objects_accordion.set_title(len(added_objects_accordion_children), \"Slab\")\n",
    "#     added_objects_accordion_children.append(utils.Text(description = \"Slab\"))\n",
    "#     added_objects_accordion.children = added_objects_accordion_children\n",
    "\n",
    "# def add_product_button_action(b):\n",
    "#     added_objects_accordion_children = list(added_objects_accordion.children)\n",
    "#     added_objects_accordion.set_title(len(added_objects_accordion_children), \"Product\")\n",
    "#     added_objects_accordion_children.append(utils.Text(description = \"Product\"))\n",
    "#     added_objects_accordion.children = added_objects_accordion_children\n",
    "\n",
    "# add_molecule_button.on_click(add_molecule_button_action)\n",
    "# add_slab_button.on_click(add_slab_button_action)\n",
    "# add_product_button.on_click(add_product_button_action)\n",
    "\n",
    "# display(add_objects_hbox)\n",
    "# display(added_objects_accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(app_widgets.object_dropdown)\n",
    "display(app_widgets.save_close_buttons_hbox)\n",
    "app_widgets.create_button.on_click(upload_simulations)\n",
    "app_widgets.quit_button.on_click(app_widgets.close_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--dx': '0.15', '--fwhms': ['0.08'], '--heights': ['4.0', '6.0'], '--wfn_file': 'parent_calc_folder/aiida-RESTART.wfn', '--xyz_file': 'parent_calc_folder/aiida.coords.xyz', '--isovalues': ['1e-7'], '--eval_cutoff': '16.0', '--eval_region': ['G', 'G', 'G', 'G', 'n-2.0_C', 'p4.0'], '--output_file': 'stm.npz', '--energy_range': ['-2.00', '2.00', '0.040'], '--hartree_file': 'parent_calc_folder/aiida-HART-v_hartree-1_0.cube', '--p_tip_ratios': 0.0, '--extrap_extent': '5.0', '--basis_set_file': 'parent_calc_folder/BASIS_MOLOPT', '--cp2k_input_file': 'parent_calc_folder/aiida.inp'}\n"
     ]
    }
   ],
   "source": [
    "# print(dict(x.inputs.spm_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
