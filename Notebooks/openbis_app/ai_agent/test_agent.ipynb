{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b924c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758725628.463087    2245 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Google LLM interface\n",
    "from langchain.tools import tool                          # Decorator to turn functions into tools\n",
    "from langgraph.prebuilt import create_react_agent         # Helper to build ReAct-style agents\n",
    "from langgraph.graph import START, StateGraph, END        # Core components of LangGraph\n",
    "from typing import TypedDict                              # Used to define structured state\n",
    "import os\n",
    "import serpapi\n",
    "\n",
    "# --- Tool Definition ---\n",
    "@tool\n",
    "def serper_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform a real-time search using the Serp API.\n",
    "\n",
    "    This tool takes a plain-text user query, sends it to Serp (a web search API),\n",
    "    and returns a string with the top relevant results. It can be used by agents\n",
    "    to gather up-to-date information from the internet as part of a reasoning or\n",
    "    research task.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): A natural language search prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of search results from Serper.\n",
    "    \"\"\"\n",
    "    client = serpapi.Client(api_key = \"70e42ca5aa9c11e7fb80cd6858cce62d6a00ceab70fc3590e2469b639be0cab9\")\n",
    "    return client.search(q=user_query, engine=\"google\")['organic_results'][0]['snippet']\n",
    "\n",
    "@tool\n",
    "def sum_numbers(a: float, b:float) -> float:\n",
    "    \"\"\"\n",
    "    A simple tool that adds two numbers.\n",
    "\n",
    "    This function takes two numerical inputs and returns their sum.\n",
    "    It can be used by agents to perform basic arithmetic operations\n",
    "    as part of a reasoning or problem-solving task.\n",
    "\n",
    "    Args:\n",
    "        a (float): The first number.\n",
    "        b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The sum of the two input numbers.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "# --- LLM Setup ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0, google_api_key=\"AIzaSyCJM3oWuaEwkQQC4V-viZCuWP8YTtmf-Kc\")\n",
    "\n",
    "# --- Define State ---\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    answer: str\n",
    "\n",
    "# --- Define Node ---\n",
    "def search_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Executes a ReAct-style agent that processes a user query.\n",
    "\n",
    "    This function takes the current state (which includes the user's question),\n",
    "    creates an agent using the Gemini language model and the `serper_search` tool,\n",
    "    then runs the agent to get a response. The final answer is returned as updated state.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): A dictionary with the user's query.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the generated answer.\n",
    "    \"\"\"\n",
    "    agent = create_react_agent(llm, [serper_search])\n",
    "    result = agent.invoke({\"messages\": state[\"user_query\"]})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}\n",
    "\n",
    "# --- Math Agent ---\n",
    "def math_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    A math-solving agent that uses the `sum_numbers` tool to get the sum of two numbers.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): Contains the user's query.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the computed answer from the LLM.\n",
    "    \"\"\"\n",
    "    print(\"--- Math Node ---\")\n",
    "    agent = create_react_agent(llm, [sum_numbers])\n",
    "    result = agent.invoke({\"messages\": state[\"user_query\"]})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}\n",
    "\n",
    "# --- Router Agent ---\n",
    "def router_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Captures a user query from the command line and updates the state.\n",
    "\n",
    "    This function acts as an input node in the LangGraph workflow. It prompts the user\n",
    "    to enter a query via the console, then stores that input in the shared state under\n",
    "    the 'user_query' key, which will be used to route to the appropriate agents.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state dictionary (can be empty or partially filled).\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state containing the user's query.\n",
    "    \"\"\"\n",
    "    print(\"--- Input Node ---\")\n",
    "    state['user_query'] = input(\"Input user query: \")\n",
    "    return state\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "agent_docs = {\n",
    "    \"search_agent\": search_agent.__doc__,\n",
    "    \"math_agent\": math_agent.__doc__\n",
    "}\n",
    "\n",
    "def routing_logic(state: AgentState) -> Literal[\"math_agent\", \"search_agent\"]:\n",
    "    \"\"\"\n",
    "    Uses the LLM to choose between 'math_agent' and 'search_agent'\n",
    "    based on the intent of the user query and the agents' docstrings.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state containing the user query.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the next node to route to.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a router agent. Your task is to choose the best agent for the job.\n",
    "    Here is the user query: {state['user_query']}\n",
    "\n",
    "    You can choose from the following agents:\n",
    "    - math_agent: {agent_docs['math_agent']}\n",
    "    - search_agent: {agent_docs['search_agent']}\n",
    "\n",
    "    Which agent should handle this query? Respond with just the agent name.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    decision = response.content.strip().lower()\n",
    "    return \"math_agent\" if \"math\" in decision else \"search_agent\"\n",
    "\n",
    "# --- Human Approval Node ---\n",
    "def approval_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Ask a human if the math agent can use the sum_numbers tool.\n",
    "    \"\"\"\n",
    "    print(\"--- Approval Node ---\")\n",
    "    while True:\n",
    "        approval = input(\"Do you allow the math agent to use the tool? (yes/no): \").strip().lower()\n",
    "        if approval in [\"yes\", \"no\"]:\n",
    "            break\n",
    "    state[\"approval\"] = approval\n",
    "    if approval == \"no\":\n",
    "        state[\"answer\"] = \"Operation cancelled by the human.\"\n",
    "    return state\n",
    "\n",
    "# --- Updated routing logic for approval ---\n",
    "def approval_routing(state: AgentState) -> Literal[\"math_agent\", END]:\n",
    "    \"\"\"\n",
    "    Decide whether to proceed to math_agent based on human approval.\n",
    "    \"\"\"\n",
    "    if state.get(\"approval\") == \"yes\":\n",
    "        return \"math_agent\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "# --- Updated Graph ---\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"router_agent\", router_agent) # Adds the new router agent to the flow\n",
    "workflow.add_node(\"search_agent\", search_agent)\n",
    "workflow.add_node(\"math_agent\", math_agent) # Adds the math agent to the flow\n",
    "workflow.add_node(\"approval_node\", approval_node)\n",
    "\n",
    "workflow.add_edge(START, \"router_agent\")\n",
    "workflow.add_conditional_edges(\"router_agent\", lambda state: \"approval_node\" if routing_logic(state) == \"math_agent\" else \"search_agent\")\n",
    "workflow.add_conditional_edges(\"approval_node\", approval_routing)\n",
    "workflow.add_edge(\"search_agent\", END)\n",
    "workflow.add_edge(\"math_agent\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c13b5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Input Node ---\n",
      "--- Approval Node ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Operation cancelled by the human.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({})[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
