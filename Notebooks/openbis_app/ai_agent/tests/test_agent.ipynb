{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b924c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758725628.463087    2245 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Google LLM interface\n",
    "from langchain.tools import tool                          # Decorator to turn functions into tools\n",
    "from langgraph.prebuilt import create_react_agent         # Helper to build ReAct-style agents\n",
    "from langgraph.graph import START, StateGraph, END        # Core components of LangGraph\n",
    "from typing import TypedDict                              # Used to define structured state\n",
    "import os\n",
    "import serpapi\n",
    "\n",
    "# --- Tool Definition ---\n",
    "@tool\n",
    "def serper_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform a real-time search using the Serp API.\n",
    "\n",
    "    This tool takes a plain-text user query, sends it to Serp (a web search API),\n",
    "    and returns a string with the top relevant results. It can be used by agents\n",
    "    to gather up-to-date information from the internet as part of a reasoning or\n",
    "    research task.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): A natural language search prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of search results from Serper.\n",
    "    \"\"\"\n",
    "    client = serpapi.Client(api_key = \"70e42ca5aa9c11e7fb80cd6858cce62d6a00ceab70fc3590e2469b639be0cab9\")\n",
    "    return client.search(q=user_query, engine=\"google\")['organic_results'][0]['snippet']\n",
    "\n",
    "@tool\n",
    "def sum_numbers(a: float, b:float) -> float:\n",
    "    \"\"\"\n",
    "    A simple tool that adds two numbers.\n",
    "\n",
    "    This function takes two numerical inputs and returns their sum.\n",
    "    It can be used by agents to perform basic arithmetic operations\n",
    "    as part of a reasoning or problem-solving task.\n",
    "\n",
    "    Args:\n",
    "        a (float): The first number.\n",
    "        b (float): The second number.\n",
    "\n",
    "    Returns:\n",
    "        float: The sum of the two input numbers.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "# --- LLM Setup ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=1.0, google_api_key=\"AIzaSyCJM3oWuaEwkQQC4V-viZCuWP8YTtmf-Kc\")\n",
    "\n",
    "# --- Define State ---\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    answer: str\n",
    "\n",
    "# --- Define Node ---\n",
    "def search_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Executes a ReAct-style agent that processes a user query.\n",
    "\n",
    "    This function takes the current state (which includes the user's question),\n",
    "    creates an agent using the Gemini language model and the `serper_search` tool,\n",
    "    then runs the agent to get a response. The final answer is returned as updated state.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): A dictionary with the user's query.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the generated answer.\n",
    "    \"\"\"\n",
    "    agent = create_react_agent(llm, [serper_search])\n",
    "    result = agent.invoke({\"messages\": state[\"user_query\"]})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}\n",
    "\n",
    "# --- Math Agent ---\n",
    "def math_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    A math-solving agent that uses the `sum_numbers` tool to get the sum of two numbers.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): Contains the user's query.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the computed answer from the LLM.\n",
    "    \"\"\"\n",
    "    print(\"--- Math Node ---\")\n",
    "    agent = create_react_agent(llm, [sum_numbers])\n",
    "    result = agent.invoke({\"messages\": state[\"user_query\"]})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}\n",
    "\n",
    "# --- Router Agent ---\n",
    "def router_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Captures a user query from the command line and updates the state.\n",
    "\n",
    "    This function acts as an input node in the LangGraph workflow. It prompts the user\n",
    "    to enter a query via the console, then stores that input in the shared state under\n",
    "    the 'user_query' key, which will be used to route to the appropriate agents.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state dictionary (can be empty or partially filled).\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state containing the user's query.\n",
    "    \"\"\"\n",
    "    print(\"--- Input Node ---\")\n",
    "    state['user_query'] = input(\"Input user query: \")\n",
    "    return state\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "agent_docs = {\n",
    "    \"search_agent\": search_agent.__doc__,\n",
    "    \"math_agent\": math_agent.__doc__\n",
    "}\n",
    "\n",
    "def routing_logic(state: AgentState) -> Literal[\"math_agent\", \"search_agent\"]:\n",
    "    \"\"\"\n",
    "    Uses the LLM to choose between 'math_agent' and 'search_agent'\n",
    "    based on the intent of the user query and the agents' docstrings.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state containing the user query.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the next node to route to.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a router agent. Your task is to choose the best agent for the job.\n",
    "    Here is the user query: {state['user_query']}\n",
    "\n",
    "    You can choose from the following agents:\n",
    "    - math_agent: {agent_docs['math_agent']}\n",
    "    - search_agent: {agent_docs['search_agent']}\n",
    "\n",
    "    Which agent should handle this query? Respond with just the agent name.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    decision = response.content.strip().lower()\n",
    "    return \"math_agent\" if \"math\" in decision else \"search_agent\"\n",
    "\n",
    "# --- Human Approval Node ---\n",
    "def approval_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Ask a human if the math agent can use the sum_numbers tool.\n",
    "    \"\"\"\n",
    "    print(\"--- Approval Node ---\")\n",
    "    while True:\n",
    "        approval = input(\"Do you allow the math agent to use the tool? (yes/no): \").strip().lower()\n",
    "        if approval in [\"yes\", \"no\"]:\n",
    "            break\n",
    "    state[\"approval\"] = approval\n",
    "    if approval == \"no\":\n",
    "        state[\"answer\"] = \"Operation cancelled by the human.\"\n",
    "    return state\n",
    "\n",
    "# --- Updated routing logic for approval ---\n",
    "def approval_routing(state: AgentState) -> Literal[\"math_agent\", END]:\n",
    "    \"\"\"\n",
    "    Decide whether to proceed to math_agent based on human approval.\n",
    "    \"\"\"\n",
    "    if state.get(\"approval\") == \"yes\":\n",
    "        return \"math_agent\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "# --- Updated Graph ---\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"router_agent\", router_agent) # Adds the new router agent to the flow\n",
    "workflow.add_node(\"search_agent\", search_agent)\n",
    "workflow.add_node(\"math_agent\", math_agent) # Adds the math agent to the flow\n",
    "workflow.add_node(\"approval_node\", approval_node)\n",
    "\n",
    "workflow.add_edge(START, \"router_agent\")\n",
    "workflow.add_conditional_edges(\"router_agent\", lambda state: \"approval_node\" if routing_logic(state) == \"math_agent\" else \"search_agent\")\n",
    "workflow.add_conditional_edges(\"approval_node\", approval_routing)\n",
    "workflow.add_edge(\"search_agent\", END)\n",
    "workflow.add_edge(\"math_agent\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c13b5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Input Node ---\n",
      "--- Approval Node ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Operation cancelled by the human.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29060c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758876686.954088   15186 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from multi_agent import OpenBISAgent\n",
    "agent = OpenBISAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b746cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Show me information about substance with empa number 704 and batch a.', additional_kwargs={}, response_metadata={}, id='3037eb8d-903a-4960-9fe7-5f844e748b9e'),\n",
       " ToolMessage(content='Successfully transferred to specific_agent', name='transfer_to_specific_agent', id='00d0592b-fac0-4e5e-a4ad-5d419f3ade97', tool_call_id='5010fbb0-4935-45d2-8db1-123f20378d70'),\n",
       " AIMessage(content='The permID of the molecule is 20250922145817954-468.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, name='specific_agent', id='run--2ec54c7f-71b2-4643-ab9b-bec6005f1cf7-0', usage_metadata={'input_tokens': 4139, 'output_tokens': 30, 'total_tokens': 4169, 'input_token_details': {'cache_read': 3695}}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, name='supervisor', id='run--a8ff4724-3527-41db-b8ce-9b3b13e798ed-0')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.ask_question(\"Show me information about substance with empa number 704 and batch a and show me all instruments that can perform STM.\")\n",
    "agent.ask_question(\"Show me information about substance with empa number 704 and batch a.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1521434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  7 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('supervisor',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('specific_agent',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('supervisor',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.get_graph_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5031df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(agent.agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73457c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758886427.703301    8539 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "import json\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.graph import START, StateGraph, MessagesState, add_messages, END\n",
    "from langgraph.types import Command\n",
    "from typing import Annotated, TypedDict, Literal, Sequence\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
    "import tools\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def create_agent(model, tools, prompt = None):\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    def chatbot(state: dict):\n",
    "        # Build initial messages\n",
    "        messages = state.get(\"messages\", [])\n",
    "\n",
    "        # If a system prompt is provided, prepend it\n",
    "        if prompt:\n",
    "            messages = [SystemMessage(content=prompt)] + messages\n",
    "\n",
    "        # Call the LLM with tools\n",
    "        response = model_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    graph_builder = StateGraph(AgentState)\n",
    "    graph_builder.add_node(\"agent\", chatbot)\n",
    "\n",
    "    tool_node = ToolNode(tools=tools)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"agent\")\n",
    "    graph_builder.set_entry_point(\"agent\")\n",
    "    return graph_builder.compile()\n",
    "\n",
    "def read_text_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "LLM_API_KEY = read_json(\"/home/jovyan/api_keys/gemini_api.json\")[\"api_key\"]\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", google_api_key = LLM_API_KEY)\n",
    "\n",
    "general_agent_prompt = read_text_file(\"data/system_prompt.txt\")\n",
    "general_agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [\n",
    "        tools.get_openbis_objects,\n",
    "        tools.get_openbis_object_by_permId,\n",
    "        tools.get_openbis_objects_by_name,\n",
    "        tools.get_openbis_objects_by_date\n",
    "    ],\n",
    "    prompt = f\"\"\"\n",
    "        {general_agent_prompt}\n",
    "        INSTRUCTIONS:\n",
    "        - Assist with general openBIS-related tasks, e.g., getting objects by type,\n",
    "        permId, name, or date.\n",
    "        - After you're done with your tasks, respond to the supervisor directly.\n",
    "        - Respond ONLY with the results of your work, do NOT include ANY other text.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def general_agent_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "    result = general_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content,\n",
    "                    name=\"general_agent\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\",\n",
    "    )\n",
    "\n",
    "specific_agent = create_react_agent(\n",
    "    model = llm,\n",
    "    tools = [\n",
    "        tools.get_live_samples_by_attributes,\n",
    "        tools.get_substances_by_attributes,\n",
    "        # tools.get_crystals_by_attributes,\n",
    "        # tools.get_2d_materials_by_attributes\n",
    "    ],\n",
    "    prompt = \"\"\"\n",
    "        You are an openBIS agent able to answer specific questions about openBIS inventories, e.g.,\n",
    "        when the user wants to find substances by attributes, or get live samples.\n",
    "        INSTRUCTIONS:\n",
    "        - Assist ONLY with specific openBIS-related tasks.\n",
    "        - After you're done with your tasks, respond to the supervisor directly.\n",
    "        - Respond ONLY with the results of your work, do NOT include ANY other text.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def specific_agent_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "    result = specific_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content,\n",
    "                    name=\"specific_agent\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\",\n",
    "    )\n",
    "\n",
    "class Supervisor(BaseModel):\n",
    "    next: Literal[\"general_agent\", \"specific_agent\"] = Field(\n",
    "        description = \"\"\"\n",
    "            Determines which specialist to active next in the workflow sequence:\n",
    "            - 'general_agent' when you need to get objects by type, permId, name or date.\n",
    "            - 'specific_agent'. when you need specific openBIS tasks, e.g. getting substances by attributes,\n",
    "            getting crystals by attributes, getting 2D materials by attributes, or getting live samples.\n",
    "        \"\"\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state: MessagesState) -> Command[Literal[\"general_agent\", \"specific_agent\"]]:\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        You are a workflow supervisor managing a team of two specialized agents: General agent and Specific agent. \n",
    "        Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state \n",
    "        and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\n",
    "\n",
    "        **Team Members**:\n",
    "        1. **General Agent**: Specializes in getting relevant openBIS objects' data needed to address the user's request. This agent only answers to general questions like getting objects by type, permId, name or date.\n",
    "        2. **Math Expert**: Specializes in getting openBIS objects by specific attributes. This agent only answers to specific questions like getting substances by attributes, getting crystals by attributes, getting 2D materials by attributes, or getting live samples.\n",
    "\n",
    "        **Your Responsibilities**:\n",
    "        1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "        2. Route the task to the most appropriate agent at each decision point.\n",
    "        3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "        4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "        Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing unnecessary steps, ultimately delivering complete and accurate solutions to user requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "\n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    print(f\"--- Workflow Transition: Supervisor → {goto.upper()} ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n",
    "    \n",
    "class Validator(BaseModel):\n",
    "    next: Literal[\"supervisor\", \"FINISH\"] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"The reason for the decision.\"\n",
    "    )\n",
    "\n",
    "def validator_node(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "\n",
    "    system_prompt = '''\n",
    "        Your task is to ensure reasonable quality.\n",
    "        Specifically, you must:\n",
    "        - Review the user's question (the first message in the workflow).\n",
    "        - Review the answer (the last message in the workflow).\n",
    "        - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "        - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "\n",
    "        - Accept answers that are \"good enough\" rather than perfect\n",
    "        - Prioritize workflow completion over perfect responses\n",
    "        - Give benefit of doubt to borderline answers\n",
    "\n",
    "        Routing Guidelines:\n",
    "        1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "        2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "    '''\n",
    "    \n",
    "    user_question = state[\"messages\"][0].content\n",
    "    agent_answer = state[\"messages\"][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "        {\"role\": \"assistant\", \"content\": agent_answer},\n",
    "    ]\n",
    "\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == \"FINISH\" or goto == END:\n",
    "        goto = END\n",
    "        print(\" --- Transitioning to END ---\")\n",
    "    else:\n",
    "        print(f\"--- Workflow Transition: Validator → Supervisor ---\")\n",
    "\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"validator\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"general_agent\", general_agent_node)\n",
    "builder.add_node(\"specific_agent\", specific_agent_node)\n",
    "builder.add_node(\"validator\", validator_node)\n",
    "\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98108afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Workflow Transition: Supervisor → GENERAL_AGENT ---\n",
      "\"******Output from node****** 'supervisor':\"\n",
      "HumanMessage(content='The user wants to retrieve all information about an object. The general agent is best suited for retrieving complete information based on an identifier.', additional_kwargs={}, response_metadata={}, name='supervisor', id='b6b25f14-a8e6-46b7-8a9c-04975997dbf7')\n",
      "\n",
      "\"******Output from node****** 'general_agent':\"\n",
      "HumanMessage(content='What is the identifier of the object that you are looking for?', additional_kwargs={}, response_metadata={}, name='general_agent', id='82e4a6e8-7c4c-4f24-aa58-775d9515c7e3')\n",
      "\n",
      "--- Workflow Transition: Validator → Supervisor ---\n",
      "\"******Output from node****** 'validator':\"\n",
      "HumanMessage(content='The answer is asking for clarification of the user request, which is appropriate.', additional_kwargs={}, response_metadata={}, name='validator', id='0132de11-2272-42b5-b804-563c30093980')\n",
      "\n",
      "--- Workflow Transition: Supervisor → GENERAL_AGENT ---\n",
      "\"******Output from node****** 'supervisor':\"\n",
      "HumanMessage(content='The user needs to clarify the object they are referring to by providing its identifier. The general agent will then retrieve the information associated with that object.', additional_kwargs={}, response_metadata={}, name='supervisor', id='eec59f5b-2166-46e6-8714-83795771237b')\n",
      "\n",
      "\"******Output from node****** 'general_agent':\"\n",
      "HumanMessage(content=\"Please provide the identifier (permId) of the object you're interested in. It follows the pattern YYYYMMDDHHMMSSmmm-####. Example: 20250717115421436-984.\", additional_kwargs={}, response_metadata={}, name='general_agent', id='58beab7d-9356-437f-9bc4-677f8c08840e')\n",
      "\n",
      "--- Workflow Transition: Validator → Supervisor ---\n",
      "\"******Output from node****** 'validator':\"\n",
      "HumanMessage(content='The answer does not provide any information about the object. It only asks for the identifier.', additional_kwargs={}, response_metadata={}, name='validator', id='5b369c62-1b46-461e-ac15-c1f96a596406')\n",
      "\n",
      "--- Workflow Transition: Supervisor → GENERAL_AGENT ---\n",
      "\"******Output from node****** 'supervisor':\"\n",
      "HumanMessage(content='The user needs to clarify the object they are referring to by providing its identifier. The general agent will then retrieve the information associated with that object.', additional_kwargs={}, response_metadata={}, name='supervisor', id='4fa18bfc-c2e5-4278-beab-d7a8437e8cae')\n",
      "\n",
      "\"******Output from node****** 'general_agent':\"\n",
      "HumanMessage(content=\"I need the object's identifier (permId) to retrieve its information. Could you please provide it? The permId follows the pattern YYYYMMDDHHMMSSmmm-#### (e.g., 20250717115421436-984).\", additional_kwargs={}, response_metadata={}, name='general_agent', id='1c06fbb1-5bf8-4ae4-833a-44133dc7193f')\n",
      "\n",
      "--- Workflow Transition: Validator → Supervisor ---\n",
      "\"******Output from node****** 'validator':\"\n",
      "HumanMessage(content='The answer requires additional information from the user.', additional_kwargs={}, response_metadata={}, name='validator', id='887c2394-6a3e-4d87-83b2-0c15de1ab82a')\n",
      "\n",
      "--- Workflow Transition: Supervisor → GENERAL_AGENT ---\n",
      "\"******Output from node****** 'supervisor':\"\n",
      "HumanMessage(content='The user needs to provide the identifier of the object. Once the identifier is provided, the general agent will be able to retrieve the information.', additional_kwargs={}, response_metadata={}, name='supervisor', id='a887c404-13b7-42b0-9693-3a30bf633c2b')\n",
      "\n",
      "\"******Output from node****** 'general_agent':\"\n",
      "HumanMessage(content=\"I need the object's identifier (permId) to retrieve its information. Could you please provide it? The permId follows the pattern YYYYMMDDHHMMSSmmm-#### (e.g., 20250717115421436-984).\", additional_kwargs={}, response_metadata={}, name='general_agent', id='270cebd0-34db-4144-838d-3b37dbd51bf6')\n",
      "\n",
      "--- Workflow Transition: Validator → Supervisor ---\n",
      "\"******Output from node****** 'validator':\"\n",
      "HumanMessage(content=\"The answer does not address the user question, since it is asking for the object's identifier to retrieve its information, when the user is asking to get all the information and not only the permID.\", additional_kwargs={}, response_metadata={}, name='validator', id='50806174-e62e-45c8-b5fe-81607faaeb65')\n",
      "\n",
      "--- Workflow Transition: Supervisor → GENERAL_AGENT ---\n",
      "\"******Output from node****** 'supervisor':\"\n",
      "HumanMessage(content='The user is asking to get all the information about an object, so the general agent is the correct agent to retrieve the information.', additional_kwargs={}, response_metadata={}, name='supervisor', id='f793203c-e8a5-4e89-a92e-284a3c0b73bc')\n",
      "\n",
      "\"******Output from node****** 'general_agent':\"\n",
      "HumanMessage(content=\"I need the object's identifier (permId) to retrieve its information. Could you please provide it? The permId follows the pattern YYYYMMDDHHMMSSmmm-#### (e.g., 20250717115421436-984).\", additional_kwargs={}, response_metadata={}, name='general_agent', id='98878869-a473-4f91-9065-e6a9a2b16274')\n",
      "\n",
      "--- Workflow Transition: Validator → Supervisor ---\n",
      "\"******Output from node****** 'validator':\"\n",
      "HumanMessage(content='The answer is not satisfactory, it requires the user to provide more information to fulfill the request.', additional_kwargs={}, response_metadata={}, name='validator', id='02c652d4-8d9f-43a2-8566-1a922024b049')\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8539/3792278511.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8539/2869612618.py\u001b[0m in \u001b[0;36msupervisor_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    163\u001b[0m     ] + state[\"messages\"]\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSupervisor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mgoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3241\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3243\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3244\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3245\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5708\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5709\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5710\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5711\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5712\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m     def _get_ls_params(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1022\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 results.append(\n\u001b[0;32m--> 840\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    841\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1090\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"max_retries\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_retries\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"location is not supported\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    870\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 },\n\u001b[1;32m     77\u001b[0m             )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     ) -> Tuple[Any, grpc.Call]:\n\u001b[0;32m-> 1192\u001b[0;31m         state, call = self._blocking(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             )\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"I want to get all the information about that, not only the permID\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in graph.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        last_message = value.get(\"messages\", [])[-1] if \"messages\" in value else None\n",
    "        if last_message:\n",
    "            pprint.pprint(f\"******Output from node****** '{key}':\")\n",
    "            pprint.pprint(last_message, indent=2, width=80, depth=None)\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
