{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "os.sys.path.append(\"/home/jovyan/work/aiida-openbis/\")\n",
    "from aiida_openbis.utils import bisutils\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to openBIS\n",
    "session = bisutils.log_in(bisurl=\"openbis\", bisuser=\"admin\", bispasswd=\"changeit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "class OpenBISDatabase:\n",
    "    def __init__(self):\n",
    "        self.session = None\n",
    "        self.schema = {\n",
    "            \"spaces\": [], \n",
    "            \"property_types\": [], \n",
    "            \"object_types\": [],\n",
    "            \"experiment_types\": [],\n",
    "            \"vocabularies\": [],\n",
    "            \"dataSetTypes\": [],\n",
    "        }\n",
    "\n",
    "    def connect_to_openbis(self, bisurl: str, bisuser: str, bispasswd: str):\n",
    "        \"\"\"Function to connect to openBIS\"\"\"\n",
    "        self.session = bisutils.log_in(\n",
    "            bisurl = bisurl, \n",
    "            bisuser = bisuser, \n",
    "            bispasswd = bispasswd\n",
    "        )\n",
    "    \n",
    "    def extract_spaces(self):\n",
    "        \"\"\"Function to extract the spaces from openBIS\"\"\"\n",
    "        spaces = self.session.get_spaces()\n",
    "\n",
    "        for space in spaces:\n",
    "            space_metadata = {\"code\": space.code, \"description\": space.description}\n",
    "            self.schema[\"spaces\"].append(space_metadata)\n",
    "\n",
    "    def extract_projects(self):\n",
    "        \"\"\"Function to extract the projects from openBIS\"\"\"\n",
    "        for index, space in enumerate(self.schema[\"spaces\"]):\n",
    "            projects = self.session.get_projects(space = space[\"code\"])\n",
    "            self.schema[\"spaces\"][index][\"projects\"] = []\n",
    "\n",
    "            for project in projects:\n",
    "                project_metadata = {\n",
    "                    \"code\": project.code\n",
    "                }\n",
    "                self.schema[\"spaces\"][index][\"projects\"].append(project_metadata)\n",
    "    \n",
    "    def extract_experiments(self):\n",
    "        \"\"\"Function to extract the experiments from openBIS\"\"\"\n",
    "        for index_space, space in enumerate(self.schema[\"spaces\"]):\n",
    "            for index_project, project in enumerate(space[\"projects\"]):\n",
    "                experiments = self.session.get_experiments(\n",
    "                    space = space[\"code\"], \n",
    "                    project = project[\"code\"]\n",
    "                )\n",
    "                self.schema[\"spaces\"][index_space][\"projects\"][index_project][\"experiments\"] = []\n",
    "\n",
    "                for experiment in experiments:\n",
    "                    experiment_metadata = {\n",
    "                        \"code\": experiment.code, \n",
    "                        \"type\": experiment.type.code,\n",
    "                        \"properties\": experiment.props.all()\n",
    "                    }\n",
    "                    self.schema[\"spaces\"][index_space][\"projects\"][index_project][\"experiments\"].append(experiment_metadata)\n",
    "                    \n",
    "    def extract_objects(self):\n",
    "        \"\"\"Function to extract the objects from openBIS\"\"\"\n",
    "        for index_space, space in enumerate(self.schema[\"spaces\"]):\n",
    "            for index_project, project in enumerate(space[\"projects\"]):\n",
    "                for index_experiment, experiment in enumerate(project[\"experiments\"]):\n",
    "                    objects = self.session.get_samples(\n",
    "                        space = space[\"code\"], \n",
    "                        experiment = f\"/{space['code']}/{project['code']}/{experiment['code']}\"\n",
    "                    )\n",
    "                    self.schema[\"spaces\"][index_space][\"projects\"][index_project][\"experiments\"][index_experiment][\"objects\"] = []\n",
    "\n",
    "                    for object in objects:\n",
    "                        object = self.session.get_object(object.permId) #TODO: Correct this easy fix once the bug of getting parents from items from get_objects() is fixed\n",
    "\n",
    "                        object_parents_identifiers = []\n",
    "                        object_children_identifiers = []\n",
    "                        object_datasets_metadata = []\n",
    "\n",
    "                        for parent in object.get_parents():\n",
    "                            object_parents_identifiers.append(parent.identifier)\n",
    "                        \n",
    "                        for child in object.get_children():\n",
    "                            object_children_identifiers.append(child.identifier)\n",
    "\n",
    "                        object_datasets = object.get_datasets()\n",
    "                        for dataset in object_datasets:\n",
    "                            dataset.data[\"dataStore\"][\"downloadUrl\"] = 'https://openbis/'\n",
    "                            dataset.download(destination = 'openBIS_datasets')\n",
    "                            object_datasets_metadata.append({\"type\": dataset.type.code, \"folderpath\": f\"openBIS_datasets/{dataset.code}\"})\n",
    "\n",
    "                        object_metadata = {\n",
    "                            \"code\": object.code, \n",
    "                            \"type\": object.type.code,\n",
    "                            \"properties\": object.props.all(),\n",
    "                            \"parents\": object_parents_identifiers,\n",
    "                            \"children\": object_children_identifiers,\n",
    "                            \"datasets\": object_datasets_metadata\n",
    "                        }\n",
    "                        self.schema[\"spaces\"][index_space][\"projects\"][index_project][\"experiments\"][index_experiment][\"objects\"].append(object_metadata)\n",
    "    \n",
    "    def extract_property_types(self):\n",
    "        \"\"\"Function to extract the property types from openBIS\"\"\"\n",
    "        for property_type in self.session.get_property_types():\n",
    "            property_type_metadata = {\n",
    "                \"code\": property_type.code,\n",
    "                \"label\": property_type.label,\n",
    "                \"description\": property_type.description,\n",
    "                \"dataType\": property_type.data_type,\n",
    "                \"vocabulary\": property_type.vocabulary,\n",
    "                \"metaData\": property_type.metaData,\n",
    "            }\n",
    "            self.schema[\"property_types\"].append(property_type_metadata)\n",
    "    \n",
    "    def extract_object_types(self):\n",
    "        \"\"\"Function to extract the object types from openBIS\"\"\"\n",
    "        for object_type in self.session.get_object_types():\n",
    "            object_properties = object_type.get_property_assignments().df\n",
    "            object_properties_metadata = []\n",
    "\n",
    "            for _, object_property in object_properties.iterrows():\n",
    "                object_properties_metadata.append(\n",
    "                    {\n",
    "                    \"section\": object_property.section,\n",
    "                    \"mandatory\": object_property.mandatory,\n",
    "                    \"prop\": object_property.propertyType,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            object_type_metadata = {\n",
    "                \"code\": object_type.code,\n",
    "                \"description\": object_type.description,\n",
    "                \"generatedCodePrefix\": object_type.generatedCodePrefix,\n",
    "                \"autoGeneratedCode\": object_type.autoGeneratedCode,\n",
    "                \"propertyAssignments\": object_properties_metadata\n",
    "            }\n",
    "            self.schema[\"object_types\"].append(object_type_metadata)\n",
    "    \n",
    "    def extract_experiment_types(self):\n",
    "        \"\"\"Function to extract the experiment types from openBIS\"\"\"\n",
    "        for experiment_type in self.session.get_experiment_types():\n",
    "            experiment_properties = experiment_type.get_property_assignments().df\n",
    "            experiment_properties_metadata = []\n",
    "\n",
    "            for _, experiment_property in experiment_properties.iterrows():\n",
    "                experiment_properties_metadata.append(\n",
    "                    {\n",
    "                    \"section\": experiment_property.section,\n",
    "                    \"mandatory\": experiment_property.mandatory,\n",
    "                    \"prop\": experiment_property.propertyType,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            experiment_type_metadata = {\n",
    "                \"code\": experiment_type.code,\n",
    "                \"description\": experiment_type.description,\n",
    "                \"propertyAssignments\": experiment_properties_metadata,\n",
    "            }\n",
    "            self.schema[\"experiment_types\"].append(experiment_type_metadata)\n",
    "\n",
    "    def extract_vocabularies(self):\n",
    "        \"\"\"Function to extract the vocabularies from openBIS\"\"\"\n",
    "        for vocabulary in self.session.get_vocabularies():\n",
    "            \n",
    "            terms_metadata = []\n",
    "            terms = vocabulary.get_terms().df\n",
    "            for _, term in terms.iterrows():\n",
    "                terms_metadata.append(\n",
    "                    {\n",
    "                    \"code\": term.code,\n",
    "                    \"label\": term.label,\n",
    "                    \"description\": term.description,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            vocabulary_metadata = {\n",
    "                \"code\": vocabulary.code,\n",
    "                \"description\": vocabulary.description,\n",
    "                \"terms\": terms_metadata,\n",
    "            }\n",
    "            self.schema[\"vocabularies\"].append(vocabulary_metadata)\n",
    "    \n",
    "    def extract_dataset_types(self):\n",
    "        for dataset_type in self.session.get_dataset_types():\n",
    "            dataset_type_properties = dataset_type.get_property_assignments().df\n",
    "            dataset_type_properties_metadata = []\n",
    "\n",
    "            for _, dataset_type_property in dataset_type_properties.iterrows():\n",
    "                dataset_type_properties_metadata.append(\n",
    "                    {\n",
    "                    \"section\": dataset_type_property.section,\n",
    "                    \"mandatory\": dataset_type_property.mandatory,\n",
    "                    \"prop\": dataset_type_property.propertyType,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            dataset_type_metadata = {\n",
    "                \"code\": dataset_type.code,\n",
    "                \"description\": dataset_type.description,\n",
    "                \"propertyAssignments\": dataset_type_properties_metadata,\n",
    "            }\n",
    "            self.schema[\"dataSetTypes\"].append(dataset_type_metadata)\n",
    "    \n",
    "    def extract_openbis_schema(self):\n",
    "        self.extract_spaces()\n",
    "        self.extract_projects()\n",
    "        self.extract_experiments()\n",
    "        self.extract_objects()\n",
    "        self.extract_property_types()\n",
    "        self.extract_object_types()\n",
    "        self.extract_experiment_types()\n",
    "        self.extract_vocabularies()\n",
    "        self.extract_dataset_types()\n",
    "    \n",
    "    def export_schema_to_json(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.schema, f, indent = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenBISDatabase instance\n",
    "openbis_database = OpenBISDatabase()\n",
    "\n",
    "# Connect to openBIS\n",
    "openbis_database.connect_to_openbis(\"openbis\", \"admin\", \"changeit\")\n",
    "\n",
    "# Extract openBIS schema\n",
    "openbis_database.extract_openbis_schema()\n",
    "\n",
    "# Dump schema into JSON file\n",
    "filename = 'openBIS_schema.json'\n",
    "openbis_database.export_schema_to_json('openBIS_schema.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/jovyan/work/aiida-openbis/Python_Scripts/openBIS_schema.json'\n",
    "with open(filename, 'r') as f:\n",
    "    openbis_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_codes_indexes = {}\n",
    "for index_space, space in enumerate(openbis_schema[\"spaces\"]):\n",
    "    for index_project, project in enumerate(space['projects']):\n",
    "        for index_experiment, experiment in enumerate(project['experiments']):\n",
    "            for index_object, object in enumerate(experiment['objects']):\n",
    "                all_objects_codes_indexes[object[\"code\"]] = [index_space, index_project, index_experiment, index_object]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"method\": \"createSpaces\", \"params\": [\"admin-231220182854644xE5E157C7C511A2C72F03BA453AA66C06\", [{\"@type\": \"as.dto.space.create.SpaceCreation\", \"code\": \"DEFAULT\", \"description\": null}]], \"id\": \"2\", \"jsonrpc\": \"2.0\"}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Space already exists in the database and needs to be unique. (Context: [])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31064/4030730652.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnew_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pybis/openbis_object.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"properties\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenbis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenbis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mVERBOSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pybis/pybis.py\u001b[0m in \u001b[0;36m_post_request\u001b[0;34m(self, resource, request)\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \"\"\"\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_request_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recover_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pybis/pybis.py\u001b[0m in \u001b[0;36m_post_request_full_url\u001b[0;34m(self, full_url, request)\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"result\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Space already exists in the database and needs to be unique. (Context: [])"
     ]
    }
   ],
   "source": [
    "for index_space, space in enumerate(openbis_schema[\"spaces\"]):\n",
    "    new_space = session.new_space(\n",
    "        code = space[\"code\"],\n",
    "        description = space[\"description\"]\n",
    "    )\n",
    "    new_space.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_objects_codes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31064/3201165653.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_objects_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEFAULT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_objects_codes' is not defined"
     ]
    }
   ],
   "source": [
    "all_objects_codes.index('DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEFAULT': [0, 0, 0, 0],\n",
       " 'BENCH': [1, 0, 0, 0],\n",
       " 'DEFAULT_STORAGE': [1, 0, 0, 1],\n",
       " 'ORDER_TEMPLATE': [1, 1, 0, 0],\n",
       " 'MOL19': [5, 0, 0, 0],\n",
       " 'MOL64': [5, 0, 0, 1],\n",
       " 'CRYS20': [5, 1, 0, 0],\n",
       " 'CRYS62': [5, 1, 0, 1],\n",
       " 'ATOM_MODEL115': [5, 2, 0, 0],\n",
       " 'ATOM_MODEL118': [5, 2, 0, 1],\n",
       " 'PUBL68': [8, 0, 0, 0],\n",
       " 'PUBL13': [8, 0, 0, 1],\n",
       " 'AUTH66': [9, 0, 0, 0],\n",
       " 'AUTH67': [9, 0, 0, 1],\n",
       " 'AUTH65': [9, 0, 0, 2],\n",
       " 'PERS1': [9, 0, 1, 0],\n",
       " 'PERS2': [9, 0, 1, 1],\n",
       " 'PERS3': [9, 0, 1, 2],\n",
       " 'PERS4': [9, 0, 1, 3],\n",
       " 'INST5': [10, 0, 0, 0],\n",
       " 'INST6': [10, 0, 0, 1],\n",
       " 'INST7': [10, 0, 0, 2],\n",
       " 'INST8': [10, 0, 0, 3],\n",
       " 'INST9': [10, 0, 0, 4],\n",
       " 'MANUFPER73': [10, 1, 0, 0],\n",
       " 'ROOM54': [10, 2, 0, 0],\n",
       " 'ROOM55': [10, 2, 0, 1],\n",
       " 'SUPPL56': [10, 3, 0, 0],\n",
       " 'SUPPL57': [10, 3, 0, 1],\n",
       " 'TRANSF35': [11, 0, 0, 0],\n",
       " 'TRANSF63': [11, 0, 0, 1],\n",
       " 'MAINT58': [11, 0, 1, 0],\n",
       " 'MAINT59': [11, 0, 1, 1],\n",
       " 'MAINT60': [11, 0, 1, 2],\n",
       " 'MAINT61': [11, 0, 1, 3],\n",
       " 'GRT52': [12, 0, 0, 0],\n",
       " 'GRT53': [12, 1, 0, 0],\n",
       " 'INSTR17': [13, 0, 0, 0],\n",
       " 'INSTR18': [13, 0, 0, 1],\n",
       " 'UHV_COMP50': [13, 0, 1, 0],\n",
       " 'UHV_COMP51': [13, 0, 1, 1],\n",
       " 'UHV_COMP48': [13, 0, 1, 2],\n",
       " 'UHV_COMP49': [13, 0, 1, 3],\n",
       " 'DRF14': [14, 0, 0, 0],\n",
       " 'ANL33': [14, 0, 0, 1],\n",
       " 'STM34': [14, 0, 0, 2],\n",
       " 'DRF16': [14, 0, 0, 3],\n",
       " 'QCM24': [14, 0, 0, 4],\n",
       " 'PREP26': [14, 0, 0, 5],\n",
       " 'SPUT27': [14, 0, 0, 6],\n",
       " 'ANL29': [14, 0, 0, 7],\n",
       " 'DEPOS30': [14, 0, 0, 8],\n",
       " 'STM31': [14, 0, 0, 9],\n",
       " 'PREP32': [14, 0, 0, 10],\n",
       " 'SIMUL116': [17, 0, 0, 0],\n",
       " 'GEO_OPT117': [17, 0, 0, 1],\n",
       " 'SIMUL119': [17, 0, 0, 2],\n",
       " 'SIMUL_STM120': [17, 0, 0, 3],\n",
       " 'DRF69': [17, 0, 1, 0],\n",
       " 'RES71': [17, 0, 2, 0],\n",
       " 'RES72': [17, 0, 2, 1],\n",
       " 'BND_SIM70': [17, 0, 3, 0],\n",
       " 'PREP36': [17, 0, 4, 0],\n",
       " 'SPUT37': [17, 0, 4, 1],\n",
       " 'ANL38': [17, 0, 4, 2],\n",
       " 'EVAP39': [17, 0, 4, 3],\n",
       " 'STM40': [17, 0, 4, 4],\n",
       " 'ANL41': [17, 0, 4, 5],\n",
       " 'SPMI42': [17, 0, 4, 6],\n",
       " 'PREP44': [17, 0, 4, 7],\n",
       " 'ANL45': [17, 0, 4, 8],\n",
       " 'STM46': [17, 0, 4, 9],\n",
       " 'SPMI47': [17, 0, 4, 10]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_objects_codes_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola\n"
     ]
    }
   ],
   "source": [
    "if ['a']:\n",
    "    print('ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permId</th>\n",
       "      <th>entityType</th>\n",
       "      <th>propertyType</th>\n",
       "      <th>predicateOntologyId</th>\n",
       "      <th>predicateOntologyVersion</th>\n",
       "      <th>predicateAccessionId</th>\n",
       "      <th>descriptorOntologyId</th>\n",
       "      <th>descriptorOntologyVersion</th>\n",
       "      <th>descriptorAccessionId</th>\n",
       "      <th>creationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "permId    entityType    propertyType    predicateOntologyId    predicateOntologyVersion    predicateAccessionId    descriptorOntologyId    descriptorOntologyVersion    descriptorAccessionId    creationDate\n",
       "--------  ------------  --------------  ---------------------  --------------------------  ----------------------  ----------------------  ---------------------------  -----------------------  --------------"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_semantic_annotations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
